{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3026c12",
   "metadata": {},
   "source": [
    "**Load Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba6a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain_groq import ChatGroq  # ✅ Perbaikan import\n",
    "import os\n",
    "\n",
    "# ✅ Ganti dengan API key Groq milikmu\n",
    "os.environ[\"GROQ_API_KEY\"] = \"YOUR_API_KEY_HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4641efff",
   "metadata": {},
   "source": [
    "**Load File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56b0f12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
     ]
    }
   ],
   "source": [
    "loader = UnstructuredFileLoader(\"proklamasi.txt\")\n",
    "documents = loader.load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a790d6b7",
   "metadata": {},
   "source": [
    "**Split Document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4db4b983",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 3224, which is longer than the specified 500\n",
      "Created a chunk of size 4663, which is longer than the specified 500\n",
      "Created a chunk of size 1469, which is longer than the specified 500\n",
      "Created a chunk of size 3417, which is longer than the specified 500\n",
      "Created a chunk of size 2087, which is longer than the specified 500\n",
      "Created a chunk of size 811, which is longer than the specified 500\n",
      "Created a chunk of size 1399, which is longer than the specified 500\n",
      "Created a chunk of size 1208, which is longer than the specified 500\n",
      "Created a chunk of size 1645, which is longer than the specified 500\n",
      "Created a chunk of size 1040, which is longer than the specified 500\n",
      "Created a chunk of size 874, which is longer than the specified 500\n",
      "Created a chunk of size 1591, which is longer than the specified 500\n",
      "Created a chunk of size 606, which is longer than the specified 500\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2764679",
   "metadata": {},
   "source": [
    "**Embeddings dan Vectorstore**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92aba8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_17496\\2354805888.py:1: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embeddings = HuggingFaceEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings()\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a923711e",
   "metadata": {},
   "source": [
    "**Retriever**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fd4d852",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d3f2e0",
   "metadata": {},
   "source": [
    "**Load Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f6992ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(temperature=0, model_name=\"llama3-70b-8192\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b2a682",
   "metadata": {},
   "source": [
    "**QnA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12dc62ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isi teks Proklamasi Kemerdekaan Indonesia adalah:\n",
      "\n",
      "\"Kami bangsa Indonesia dengan ini menyatakan kemerdekaan Indonesia. Hal-hal yang mengenai pemindahan kekuasaan dan lain-lain diselenggarakan dengan cara seksama dan dalam tempo yang sesingkat-singkatnya. Jakarta, 17 - 8 - '05 Wakil2 bangsa Indonesia, Soekarno – Hatta\"\n"
     ]
    }
   ],
   "source": [
    "qa_chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "query = \"Apa isi dari teks proklamasi kemerdekaan Indonesia?\"\n",
    "docs_relevant = retriever.get_relevant_documents(query)\n",
    "response = qa_chain.run(input_documents=docs_relevant, question=query)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1d40359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pertanyaan: Apa isi dari teks proklamasi kemerdekaan Indonesia?\n",
      "Jawaban: Isi teks Proklamasi Kemerdekaan Indonesia adalah:\n",
      "\n",
      "\"Kami bangsa Indonesia dengan ini menyatakan kemerdekaan Indonesia. Hal-hal yang mengenai pemindahan kekuasaan dan lain-lain diselenggarakan dengan cara seksama dan dalam tempo yang sesingkat-singkatnya. Jakarta, 17 - 8 - '05 Wakil2 bangsa Indonesia, Soekarno – Hatta\"\n",
      "--------------------------------------------------\n",
      "Pertanyaan: Siapa yang menandatangani teks proklamasi?\n",
      "Jawaban: Menurut teks, yang menandatangani teks Proklamasi Otentik adalah Ir. Soekarno dan Drs. Mohammad Hatta.\n",
      "--------------------------------------------------\n",
      "Pertanyaan: Kapan proklamasi kemerdekaan Indonesia dibacakan?\n",
      "Jawaban: Proklamasi kemerdekaan Indonesia dibacakan pada tanggal 17 Agustus 1945.\n",
      "--------------------------------------------------\n",
      "Pertanyaan: Mengapa teks proklamasi menggunakan ejaan lama?\n",
      "Jawaban: Teks proklamasi tidak menggunakan ejaan lama. Teks proklamasi yang asli, yaitu Naskah Proklamasi Klad, menggunakan ejaan yang berlaku pada masa itu, yaitu ejaan Van Ophuijsen. Ejaan ini digunakan di Indonesia sebelum tahun 1947.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "qa_chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "questions = [\n",
    "    \"Apa isi dari teks proklamasi kemerdekaan Indonesia?\",\n",
    "    \"Siapa yang menandatangani teks proklamasi?\",\n",
    "    \"Kapan proklamasi kemerdekaan Indonesia dibacakan?\",\n",
    "    \"Mengapa teks proklamasi menggunakan ejaan lama?\"\n",
    "]\n",
    "\n",
    "for query in questions:\n",
    "    docs_relevant = retriever.get_relevant_documents(query)\n",
    "    response = qa_chain.run(input_documents=docs_relevant, question=query)\n",
    "    print(f\"Pertanyaan: {query}\")\n",
    "    print(f\"Jawaban: {response}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d5ecf1",
   "metadata": {},
   "source": [
    "**Save Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a200a4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"retriever.pkl\", \"wb\") as f:\n",
    "    pickle.dump(retriever, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556e02df",
   "metadata": {},
   "source": [
    "**Load Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01594d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"retriever.pkl\", \"rb\") as f:\n",
    "    retriever = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f883ec0e",
   "metadata": {},
   "source": [
    "Analisis\n",
    "Proyek ini sudah berhasil menjalankan sistem RAG sederhana dengan memanfaatkan LangChain, FAISS, dan LLM dari Groq. Sistem bisa mengambil informasi dari dokumen dan menjawab pertanyaan dengan cukup baik. Namun, masih ada keterbatasan, seperti proses input data yang masih manual dan tampilan yang hanya bisa digunakan lewat notebook.\n",
    "\n",
    "Rekomendasi\n",
    "Agar lebih mudah digunakan, disarankan membuat tampilan antarmuka seperti web sederhana. Selain itu, sebaiknya sistem bisa memperbarui data secara otomatis tanpa upload manual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27feb7ff",
   "metadata": {},
   "source": [
    "Jawaban Pertanyaan\n",
    "1. Mengapa menggunakan LLM tersebut?\n",
    "LLM seperti llama3-8b-8192 digunakan karena memiliki kemampuan memahami konteks dalam teks panjang dengan baik, efisien secara komputasi, dan cocok untuk kebutuhan retrieval-augmented generation (RAG) berbahasa Indonesia. Model ini juga mudah diakses melalui Groq yang menawarkan kecepatan inferensi tinggi.\n",
    "\n",
    "2. Mengapa memilih model embedding tersebut?\n",
    "Model embedding dari sentence-transformers (HuggingFaceEmbeddings) dipilih karena telah terlatih untuk merepresentasikan semantik teks secara akurat ke dalam bentuk vektor, mendukung bahasa Indonesia, serta kompatibel dengan berbagai framework retrieval seperti FAISS.\n",
    "\n",
    "3. Mengapa memilih vector DB tersebut?\n",
    "FAISS dipilih sebagai vector database karena bersifat open-source, ringan, cepat dalam pencarian vektor mirip (nearest neighbor), dan mudah diintegrasikan dengan pipeline NLP seperti LangChain. Cocok untuk skenario aplikasi RAG berskala kecil hingga menengah.\n",
    "\n",
    "4. Bagaimana melakukan update knowledge base?\n",
    "Knowledge base dapat diperbarui dengan menambahkan dokumen baru ke dalam vector store, menghitung embedding-nya menggunakan model yang sama, lalu menggabungkannya dengan data sebelumnya di FAISS. Pembaruan ini tidak perlu melakukan retraining ulang seluruh sistem.\n",
    "\n",
    "5. Apa saja kekurangan dari aplikasi RAG yang dikembangkan?\n",
    "Beberapa kekurangannya meliputi keterbatasan konteks jika jumlah token terlalu besar, hasil jawaban sangat tergantung pada kualitas dan relevansi dokumen yang terindeks, serta tidak mendukung reasoning kompleks jika data sumber tidak lengkap. Selain itu, pembaruan skala besar dapat memerlukan reindexing ulang."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
